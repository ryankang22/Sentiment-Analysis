{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.listdir(\"./input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!head \"./input/amazon_cells_labelled.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import spacy \n",
    "import numpy \n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#read in dataset\n",
    "amazon = pd.read_csv(\"amazon_cells_labelled.txt\", sep='\\t', header=None)\n",
    "imdb = pd.read_csv(\"imdb_labelled.txt\", sep='\\t', header=None)\n",
    "yelp = pd.read_csv(\"yelp_labelled.txt\", sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  So there is no way for me to plug it in here i...  0\n",
       "1                        Good case, Excellent value.  1\n",
       "2                             Great for the jawbone.  1\n",
       "3  Tied to charger for conversations lasting more...  0\n",
       "4                                  The mic is great.  1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  A very, very, very slow-moving, aimless movie ...  0\n",
       "1  Not sure who was more lost - the flat characte...  0\n",
       "2  Attempting artiness with black & white and cle...  0\n",
       "3       Very little music or anything to speak of.    0\n",
       "4  The best scene in the movie was when Gerardo i...  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(748, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0                           Wow... Loved this place.  1\n",
       "1                                 Crust is not good.  0\n",
       "2          Not tasty and the texture was just nasty.  0\n",
       "3  Stopped by during the late May bank holiday of...  1\n",
       "4  The selection on the menu was great and so wer...  1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine imdb and yelp dataset\n",
    "train_data = pd.concat([imdb, yelp])\n",
    "train_data.columns = ['review', 'label']\n",
    "\n",
    "\n",
    "test_data = amazon\n",
    "test_data.columns = ['review', 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1748, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  A very, very, very slow-moving, aimless movie ...      0\n",
       "1  Not sure who was more lost - the flat characte...      0\n",
       "2  Attempting artiness with black & white and cle...      0\n",
       "3       Very little music or anything to speak of.        0\n",
       "4  The best scene in the movie was when Gerardo i...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_review = train_data['review'].values\n",
    "test_review = test_data['review'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing (review):\n",
    "    \n",
    "    clean_reviews = []\n",
    "    \n",
    "    for sentence in review:\n",
    "        \n",
    "        #remove numbers\n",
    "        cleaned_sen = re.sub(r'\\d+', ' ', sentence)\n",
    "        \n",
    "        #remove special characters\n",
    "        cleaned_sen = re.sub(r'[^\\w\\s]', ' ', cleaned_sen)\n",
    "        \n",
    "        #remove single characters \n",
    "        cleaned_sen = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', cleaned_sen)\n",
    "        \n",
    "        #convert to lowercase\n",
    "        cleaned_sen = cleaned_sen.lower()\n",
    "        \n",
    "        docs = nlp(cleaned_sen)\n",
    "        \n",
    "        #remove stop words and whitespaces\n",
    "        words = [token.text for token in docs if not token.is_stop | token.is_space]\n",
    "        \n",
    "        new_words = ' '.join(words)\n",
    "        \n",
    "        clean_reviews.append(new_words)\n",
    "        \n",
    "    return clean_reviews\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_review = preprocessing(train_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slow moving aimless movie distressed drifting young man\n"
     ]
    }
   ],
   "source": [
    "print(clean_train_review[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatisation process \n",
    "def  lemmatizer (review):\n",
    "    \n",
    "    clean_review = []\n",
    "    \n",
    "    for sentence in review:\n",
    "        \n",
    "        lemma = nlp(sentence)\n",
    "        \n",
    "        words = [word.lemma_ for word in lemma]\n",
    "        \n",
    "        clean_review.append(' '.join(words))\n",
    "        \n",
    "    return clean_review\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_review = lemmatizer(clean_train_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slow move aimless movie distress drift young man</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sure lose flat character audience nearly half ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>attempt artiness black white clever camera ang...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>little music speak</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>good scene movie gerardo try find song keep ru...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  labels\n",
       "0   slow move aimless movie distress drift young man       0\n",
       "1  sure lose flat character audience nearly half ...       0\n",
       "2  attempt artiness black white clever camera ang...       0\n",
       "3                                 little music speak       0\n",
       "4  good scene movie gerardo try find song keep ru...       1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new dataframe for cleaned reviews\n",
    "train_clean = pd.DataFrame(clean_train_review)\n",
    "train_clean.columns = ['reviews']\n",
    "train_clean['labels'] = train_data['label'].values\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_review = preprocessing(test_review)\n",
    "\n",
    "clean_test_review = lemmatizer(clean_test_review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>way plug converter</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good case excellent value</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>great jawbone</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tied charger conversation last minute major pr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mic great</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  labels\n",
       "0                                 way plug converter       0\n",
       "1                          good case excellent value       1\n",
       "2                                      great jawbone       1\n",
       "3  tied charger conversation last minute major pr...       0\n",
       "4                                          mic great       1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create new dataframe for cleaned reviews\n",
    "test_clean = pd.DataFrame(clean_test_review)\n",
    "test_clean.columns = ['reviews']\n",
    "test_clean['labels'] = test_data['label'].values\n",
    "test_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_words = ''.join(clean_train_review).split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the 10 most frequent word in the training set\n",
    "word_freq = Counter(list_words)\n",
    "freq_words = word_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('movie', 143), ('film', 136), ('good', 110), ('like', 85), ('great', 73), ('bad', 71), ('food', 68), ('time', 65), ('place', 57), ('character', 48)]\n"
     ]
    }
   ],
   "source": [
    "print(freq_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_clean['labels'].values\n",
    "y_test = test_clean['labels'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data to be used as input for machine learning models\n",
    "#using countVecotrizer to create vocabulary of uniques words from reviews\n",
    "count_vectorizer = CountVectorizer(stop_words = 'english')\n",
    "count_vectorizer.fit(clean_train_review)\n",
    "X_train_c = count_vectorizer.transform(clean_train_review)\n",
    "X_test_c = count_vectorizer.transform(clean_test_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use vocabulary to create feature vector for each sentences in reviews.\n",
    "tfidf_transform=TfidfTransformer()\n",
    "X_train = tfidf_transform.fit_transform(X_train_c)\n",
    "X_test = tfidf_transform.fit_transform(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:548: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 531, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1304, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 442, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\kangj\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Param:  {'C': 1, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "#Build logistic model using gridsearchcv to find optimal parameters\n",
    "lr = LogisticRegression()\n",
    "\n",
    "param_grid = {\"C\":[0.001, 0.01, 0.1, 1, 10, 100], \"penalty\":[\"l1\",\"l2\"]}\n",
    "\n",
    "grid_search = GridSearchCV(lr, param_grid, cv=5, scoring = 'accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Param: \", grid_search.best_params_ )  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = LogisticRegression(C= 1, penalty = 'l2')\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.83      0.78       500\n",
      "           1       0.81      0.71      0.76       500\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.78      0.77      0.77      1000\n",
      "weighted avg       0.78      0.77      0.77      1000\n",
      "\n",
      "Model's Accuracy:  0.771\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "cm_test = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Model's Accuracy: \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm_model = confusion_matrix(y_true = y_test, y_pred = y_pred)\n",
    "f, ax = plt.subplots(figsize=(5, 4))\n",
    "sns.heatmap(cm_model, annot=True, linewidths=.5, fmt= '.1f',ax=ax);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
